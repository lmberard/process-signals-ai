{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83e21c9",
   "metadata": {},
   "source": [
    "# # TP10: Multinomial Naive Bayes\n",
    "\n",
    "**Alumna**: Lucia Berard\n",
    "\n",
    "**Fecha**: 15/06/2025\n",
    "\n",
    "[Link a Google Colab](https://colab.research.google.com/drive/1ah4GT2vGlptvJM9qctPRs0NpqqozR07z?usp=sharing)\n",
    "\n",
    "\n",
    "La base de datos *BuzzFeed-Webis Fake News Corpus 2016* posee diferentes art√≠culos period√≠sticos de una semana cercana a las elecciones estadounidenses de ese a√±o. Se desea entrenar un algoritmo Multinomial Naive Bayes capaz de clasificar los art√≠culos en: ‚Äúmayormente falso‚Äù, ‚Äúmayormente verdadero‚Äù, ‚Äúmezcla de verdadero y falso‚Äù y ‚Äúsin contenido factual‚Äù.\n",
    "\n",
    "![Banner UNICEF Argentina](https://www.unicef.org/argentina/sites/unicef.org.argentina/files/styles/media_banner/public/3%20%282%29.webp?itok=czU8qvE-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dabfe5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.6.1\n",
      "numpy: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print('sklearn:', sklearn.__version__)\n",
    "print('numpy:', np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d1ed4",
   "metadata": {},
   "source": [
    "____\n",
    "## (a) Exploraci√≥n de datos:\n",
    "\n",
    "#### a.1) Descargar la base de datos en https://zenodo.org/record/1239675/files/articles.zip?download=1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38d25e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "Archive:  articles.zip\n"
     ]
    }
   ],
   "source": [
    "!wget -nc 'https://zenodo.org/record/1239675/files/articles.zip?download=1' -O articles.zip\n",
    "!unzip -n articles.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c4e4b",
   "metadata": {},
   "source": [
    "\n",
    "#### a.2) Construir la base de datos. Puede usar el siguiente c√≥digo:\n",
    "\n",
    "```python\n",
    "import xml.etree.ElementTree as ET\n",
    "data = {\"mainText\": [], \"orientation\": [], \"veracity\": []}\n",
    "\n",
    "for filename in os.listdir(\"articles/\"):\n",
    "    root = ET.parse(f\"articles/{{filename}}\").getroot()\n",
    "    for elem in root:\n",
    "        if elem.tag in data.keys():\n",
    "                data[elem.tag].append(elem.text)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    data = data[data.notna().all(axis=\"columns\")]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "690a2cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mainText</th>\n",
       "      <th>orientation</th>\n",
       "      <th>veracity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Millions of people tuned in Monday night to wa...</td>\n",
       "      <td>left</td>\n",
       "      <td>mostly true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Clintons understand the average American. ...</td>\n",
       "      <td>right</td>\n",
       "      <td>mixture of true and false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harassment is known in Arabic as ‚Äòtaharrush‚Äô. ...</td>\n",
       "      <td>right</td>\n",
       "      <td>mixture of true and false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democratic President Barack Obama pulled off a...</td>\n",
       "      <td>left</td>\n",
       "      <td>mostly true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic nominee Hillary Clinton knows her f...</td>\n",
       "      <td>left</td>\n",
       "      <td>mostly true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mainText orientation  \\\n",
       "0  Millions of people tuned in Monday night to wa...        left   \n",
       "1  The Clintons understand the average American. ...       right   \n",
       "2  Harassment is known in Arabic as ‚Äòtaharrush‚Äô. ...       right   \n",
       "3  Democratic President Barack Obama pulled off a...        left   \n",
       "4  Democratic nominee Hillary Clinton knows her f...        left   \n",
       "\n",
       "                    veracity  \n",
       "0                mostly true  \n",
       "1  mixture of true and false  \n",
       "2  mixture of true and false  \n",
       "3                mostly true  \n",
       "4                mostly true  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"mainText\": [], \"orientation\": [], \"veracity\": []}\n",
    "\n",
    "for filename in os.listdir(\"articles/\"):\n",
    "    root = ET.parse(f\"articles/{filename}\").getroot()\n",
    "    for elem in root:\n",
    "        if elem.tag in data.keys():\n",
    "            data[elem.tag].append(elem.text)\n",
    "\n",
    "# Convertir a DataFrame y eliminar filas con valores nulos\n",
    "df = pd.DataFrame(data)\n",
    "df = df[df.notna().all(axis=\"columns\")]\n",
    "\n",
    "print(\"Primeras filas del DataFrame:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6e449",
   "metadata": {},
   "source": [
    "\n",
    "#### a.3) Utilice el comando `train_test_split` (sklearn) para definir dos conjuntos de datos. El conjunto de entrenamiento debe contener el 80% de las muestras, el resto ser√° de testeo.\n",
    "\n",
    "Para definir el 80% de las muestras, utilice el par√°metro `test_size=0.2` que indica el porcentaje de muestras que se utilizar√°n para el testeo.\n",
    "\n",
    "#### a.4) Utilizando `CountVectorizer` (sklearn) pre-procesar los datos del texto principal de los art√≠culos. Se recomienda convertir el texto a min√∫scula, utilizar como `stop_words` las palabras est√°ndar del idioma ingl√©s, eliminar las palabras que aparecen en m√°s del 60% de los documentos y descartar las palabras vistas en menos de 3 documentos.\n",
    "\n",
    "[`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) de `sklearn` convierte una colecci√≥n de documentos de texto en una matriz de conteo de palabras. Esto significa que toma un conjunto de textos y los transforma en una matriz, donde cada columna representa una palabra distinta del vocabulario y cada fila representa un documento. El valor en cada celda es la cantidad de veces que aparece esa palabra en ese documento.\n",
    "\n",
    "Por ejemplo, si tengo tres textos: \"hola mundo\", \"hola\" y \"mundo hola hola\"\n",
    "\n",
    "El `CountVectorizer` generar√° una matriz como esta:\n",
    "\n",
    "| | hola | mundo |\n",
    "|------|------|-------|\n",
    "| doc1 | 1 | 1 | \n",
    "| doc2 | 1 | 0 |\n",
    "| doc3 | 2 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99575c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del set de entrenamiento: (1283, 11191) \n",
      "(Significa que tiene 1283 documentos, 80.0% del total)\n",
      "Forma del set de testeo: (321, 11191) \n",
      "(Significa que tiene 321 documentos, 20.0% del total)\n",
      "Distribuci√≥n de clases para 'veracity':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cantidad</th>\n",
       "      <th>Porcentaje</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veracity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixture of true and false</th>\n",
       "      <td>209</td>\n",
       "      <td>13.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostly false</th>\n",
       "      <td>82</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostly true</th>\n",
       "      <td>1249</td>\n",
       "      <td>77.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no factual content</th>\n",
       "      <td>64</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Cantidad  Porcentaje\n",
       "veracity                                       \n",
       "mixture of true and false       209       13.03\n",
       "mostly false                     82        5.11\n",
       "mostly true                    1249       77.87\n",
       "no factual content               64        3.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de clases para 'orientation':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cantidad</th>\n",
       "      <th>Porcentaje</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>252</td>\n",
       "      <td>15.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mainstream</th>\n",
       "      <td>822</td>\n",
       "      <td>51.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>530</td>\n",
       "      <td>33.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Cantidad  Porcentaje\n",
       "orientation                      \n",
       "left              252       15.71\n",
       "mainstream        822       51.25\n",
       "right             530       33.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separar en conjuntos de entrenamiento y testeo (80%/20%)\n",
    "X = df[\"mainText\"]\n",
    "y = df[\"veracity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# test_size=0.2: 20% de los datos para testeo\n",
    "# random_state=42: el numero es arbitrario, el objetivo es que el resultado sea reproducible\n",
    "\n",
    "# Preprocesamiento con CountVectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english', # Elijo ingles como idioma\n",
    "    max_df=0.6,    # Elimino palabras que aparecen en m√°s del 60% de los documentos\n",
    "    min_df=3       # Eliminp palabras que aparecen en menos de 3 documentos\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "n_total = len(df)\n",
    "n_train = X_train_vec.shape[0]\n",
    "n_test = X_test_vec.shape[0]\n",
    "\n",
    "pct_train = n_train / n_total * 100\n",
    "pct_test = n_test / n_total * 100\n",
    "\n",
    "print(f\"Forma del set de entrenamiento: {X_train_vec.shape} \"\n",
    "      f\"\\n(Significa que tiene {n_train} documentos, {pct_train:.1f}% del total)\")\n",
    "print(f\"Forma del set de testeo: {X_test_vec.shape} \"\n",
    "      f\"\\n(Significa que tiene {n_test} documentos, {pct_test:.1f}% del total)\")\n",
    "\n",
    "# Funcion para mostrar la distribuci√≥n de clases\n",
    "def show_distribution(df, column, name=None):\n",
    "    \"\"\"\n",
    "    Muestra la distribuci√≥n de clases de una columna de un DataFrame.\n",
    "    \"\"\"\n",
    "    counts = df[column].value_counts().sort_index()\n",
    "    percent = df[column].value_counts(normalize=True).sort_index() * 100\n",
    "    distribucion = pd.DataFrame({\n",
    "        \"Cantidad\": counts,\n",
    "        \"Porcentaje\": percent.round(2)\n",
    "    })\n",
    "    if name is None:\n",
    "        name = column\n",
    "    print(f\"Distribuci√≥n de clases para '{name}':\")\n",
    "    display(distribucion)\n",
    "\n",
    "show_distribution(df, \"veracity\")\n",
    "show_distribution(df, \"orientation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52660de",
   "metadata": {},
   "source": [
    "Se verifica que el set de entrenamiento tiene 1283 documentos y el de testeo 321 documentos, de un total de 1604 documentos, por lo que cumple el ratio de 80/20. \n",
    "\n",
    "Adem√°s, se analiz√≥ la distribuci√≥n de las clases de veracidad y orientaci√≥n. Por ejemplo, la mayor√≠a de los textos (77.87%) son \"mostly true\" y la mayor√≠a de las orientaciones (51.25%) son \"mainstream\".\n",
    "\n",
    "Se nota que los valores para veracidad son m√°s desiguales que los para orientaci√≥n, lo cual podr√≠a indicar que hay un sesgo en el dataset y que los datos pueden generar problemas en los siguientes resultados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ef365",
   "metadata": {},
   "source": [
    "\n",
    "## (b) Entrenamiento:\n",
    "\n",
    "Implementar un MNB de $\\alpha = (1, 1, \\cdots, 1)$ que prediga la veracidad de un art√≠culo a partir de su texto principal (pre-procesado). El c√≥digo debe estar estructurado de la siguiente manera:\n",
    "\n",
    "```python\n",
    "class MNB:\n",
    "    # Inicializar atributos y declarar hiperpar√°metros\n",
    "    def __init__(self,...):\n",
    "        ...\n",
    "\n",
    "    # Etapa de entrenamiento\n",
    "    def fit(self,X,y):\n",
    "        ...\n",
    "\n",
    "    # Etapa de testeo soft\n",
    "    def predict_proba(self,X):\n",
    "        ...\n",
    "\n",
    "    # Etapa de testeo hard (no repetir c√≥digo)\n",
    "    def predict(self,X):\n",
    "        ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55069816",
   "metadata": {},
   "source": [
    "\n",
    "`MNB: Multinomial Naive Bayes`\n",
    "\n",
    "El modelo Multinomial Naive Bayes asume que las palabras de un documento son independientes entre s√≠; es decir, la aparici√≥n de una palabra no afecta la probabilidad de aparici√≥n de otra (de ah√≠ el t√©rmino \"Naive\"). El objetivo es modelar la distribuci√≥n multinomial de las palabras en los diferentes documentos del dataset.\n",
    "\n",
    "**Teorema de Bayes**\n",
    "\n",
    "El teorema de Bayes nos dice que:\n",
    "\n",
    "$$ P(\\text{clase} \\mid \\text{documento}) = \\frac{P(\\text{documento} \\mid \\text{clase}) \\times P(\\text{clase})}{P(\\text{documento})} $$\n",
    "\n",
    "Para clasificar, buscamos la clase que maximiza esta probabilidad:\n",
    "\n",
    "$$ \\text{clase}_{\\text{predicha}} = \\arg\\max{\\left[P(\\text{clase} \\mid \\text{documento})\\right]} $$\n",
    "\n",
    "Como $P(\\text{documento})$ es constante para todas las clases, se puede omitir en la maximizaci√≥n:\n",
    "\n",
    "$$ \\text{clase}_{\\text{predicha}} = \\arg\\max{\\left[P(\\text{documento} \\mid \\text{clase}) \\times P(\\text{clase})\\right]} $$\n",
    "\n",
    "Aplicando logaritmos (para mayor estabilidad num√©rica):\n",
    "\n",
    "$$ \\text{clase}_{\\text{predicha}} = \\arg\\max{\\left[ \\log P(\\text{clase}) + \\log P(\\text{documento} \\mid \\text{clase}) \\right]} $$\n",
    "\n",
    "En el caso del modelo multinomial, la verosimilitud del documento dada la clase se calcula como:\n",
    "\n",
    "$$ \\log P(\\text{documento} \\mid \\text{clase}) = \\sum_{i} \\text{count}(\\text{palabra}_i) \\times \\log P(\\text{palabra}_i \\mid \\text{clase}) $$\n",
    "\n",
    "Para realizar el MNB, se siguen los siguientes pasos:\n",
    "\n",
    "1. fit(X, y): Aprende las probabilidades a partir de los datos de entrenamiento:\n",
    "    - Calcula la probabilidad de cada clase (P(clase), frecuencia de cada clase).\n",
    "    - Calcula la probabilidad de cada palabra dado cada clase (P(palabra|clase)) usando suavizado de Laplace:\n",
    "    $$ P(\\text{palabra}_i | \\text{clase}) = \\frac{\\text{count}(\\text{palabra}_i, \\text{clase}) + \\alpha}{\\sum_j \\text{count}(\\text{palabra}_j, \\text{clase}) + V \\cdot \\alpha} $$ \n",
    "    donde $V$ es el tama√±o del vocabulario.\n",
    "\n",
    "2. predict_proba(X): Para cada documento, calcula la probabilidad (o log-probabilidad) de que pertenezca a cada clase usando la f√≥rmula de Bayes. Se suele trabajar en log-probabilidades para evitar underflow num√©rico:\n",
    "$$ \\log P(\\text{clase}) + \\sum_{i} \\text{count}(\\text{palabra}_i) \\cdot \\log P(\\text{palabra}_i | \\text{clase}) $$\n",
    "\n",
    "3. predict(X): Devuelve la clase con mayor probabilidad para cada documento (usa los resultados de predict_proba).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba91db",
   "metadata": {},
   "source": [
    "\n",
    "## (c) Inferencia\n",
    "\n",
    "Implementar un m√©todo a la clase anterior que calcule el *accuracy* y la *Macro-F1*. Evaluar dichas m√©tricas en el conjunto de testeo. ¬øPor qu√© dan tan diferentes? Para el c√°lculo de la F1 debe considerar el caso de *precision* y *recall* nulas.\n",
    "\n",
    "**M√©tricas**\n",
    "\n",
    "- Accuracy: Proporci√≥n de documentos correctamente clasificados.\n",
    "- Macro-F1: F1-score promedio por clase, sin ponderar por cantidad de ejemplos por clase.\n",
    "\n",
    "Para cada clase, calcula:\n",
    "\n",
    "- Precision = $\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$ Mide la calidad de las predicciones positivas \n",
    "- Recall = $\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$ Mide la capacidad del modelo para encontrar todos los positivos reales \n",
    "- F1 = $\\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$ Combina ambas m√©tricas en un solo valor, es un promedio balanceado de ambas. Si Precision o Recall son nulos, el F1 para esa clase es 0. \n",
    "\n",
    "\n",
    "\n",
    "**¬øPor qu√© pueden diferir tanto accuracy y Macro-F1?**\n",
    "- Accuracy mide el porcentaje total de aciertos, pero puede estar sesgado si hay clases desbalanceadas (por ejemplo, si una clase es muy frecuente).\n",
    "- Macro-F1 promedia el F1 de cada clase, d√°ndole igual peso a todas, incluso a las minoritarias. Si el modelo ignora clases poco frecuentes, la Macro-F1 ser√° baja aunque el accuracy sea alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06994968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6791277258566978\n",
      "Macro-F1: 0.3717473328129066\n",
      "\n",
      "M√©tricas por clase:\n",
      "mixture of true and false:\n",
      "  Precision: 0.2297\n",
      "  Recall: 0.3542\n",
      "  F1-score: 0.2787\n",
      "mostly false:\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.0588\n",
      "  F1-score: 0.1111\n",
      "mostly true:\n",
      "  Precision: 0.8182\n",
      "  Recall: 0.8049\n",
      "  F1-score: 0.8115\n",
      "no factual content:\n",
      "  Precision: 0.5000\n",
      "  Recall: 0.2000\n",
      "  F1-score: 0.2857\n"
     ]
    }
   ],
   "source": [
    "class MNB:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_log_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.asarray(y)\n",
    "        self.classes_, class_counts = np.unique(y, return_counts=True)\n",
    "        n_classes = len(self.classes_)\n",
    "        n_features = X.shape[1]\n",
    "        self.n_features_ = n_features\n",
    "\n",
    "        self.class_log_prior_ = np.log(class_counts) - np.log(class_counts.sum())\n",
    "\n",
    "        feature_count = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        for idx, c in enumerate(self.classes_):\n",
    "            feature_count[idx, :] = X[y == c].sum(axis=0)\n",
    "\n",
    "        smoothed_fc = feature_count + self.alpha\n",
    "        smoothed_cc = smoothed_fc.sum(axis=1, keepdims=True)\n",
    "        self.feature_log_prob_ = np.log(smoothed_fc) - np.log(smoothed_cc)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        return jll\n",
    "\n",
    "    def predict(self, X):\n",
    "        jll = self.predict_proba(X)\n",
    "        idx = np.argmax(jll, axis=1)\n",
    "        return self.classes_[idx]\n",
    "\n",
    "    def _joint_log_likelihood(self, X):\n",
    "        return (X @ self.feature_log_prob_.T) + self.class_log_prior_\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n",
    "\n",
    "    def macro_f1(self, X, y):\n",
    "        _, _, f1s = self.per_class_metrics(X, y)\n",
    "        return np.mean(f1s)\n",
    "\n",
    "    def per_class_metrics(self, X, y):\n",
    "        \"\"\"\n",
    "        Devuelve arrays de precision, recall y F1 para cada clase.\n",
    "        \"\"\"\n",
    "        y_true = np.asarray(y)\n",
    "        y_pred = self.predict(X)\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        for c in self.classes_:\n",
    "            tp = np.sum((y_pred == c) & (y_true == c))\n",
    "            fp = np.sum((y_pred == c) & (y_true != c))\n",
    "            fn = np.sum((y_pred != c) & (y_true == c))\n",
    "            if tp + fp == 0:\n",
    "                precision = 0.0\n",
    "            else:\n",
    "                precision = tp / (tp + fp)\n",
    "            if tp + fn == 0:\n",
    "                recall = 0.0\n",
    "            else:\n",
    "                recall = tp / (tp + fn)\n",
    "            if precision + recall == 0:\n",
    "                f1 = 0.0\n",
    "            else:\n",
    "                f1 = 2 * precision * recall / (precision + recall)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "        return np.array(precisions), np.array(recalls), np.array(f1_scores)\n",
    "\n",
    "    def classification_report(self, X, y):\n",
    "        \"\"\"\n",
    "        Devuelve un diccionario con accuracy, macro_f1, y arrays de precisi√≥n, recall y F1 por clase.\n",
    "        \"\"\"\n",
    "        acc = self.accuracy(X, y)\n",
    "        macro_f1 = self.macro_f1(X, y)\n",
    "        precisions, recalls, f1_scores = self.per_class_metrics(X, y)\n",
    "        return {\n",
    "            \"accuracy\": acc,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"precisions\": precisions,\n",
    "            \"recalls\": recalls,\n",
    "            \"f1_scores\": f1_scores,\n",
    "            \"classes\": self.classes_\n",
    "        }\n",
    "\n",
    "def ensure_dense(X):\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        return X.toarray()\n",
    "    return np.array(X)\n",
    "\n",
    "mnb = MNB(alpha=1)\n",
    "X_train_dense = ensure_dense(X_train_vec)\n",
    "X_test_dense = ensure_dense(X_test_vec)\n",
    "mnb.fit(X_train_dense, y_train)\n",
    "\n",
    "report = mnb.classification_report(X_test_dense, y_test)\n",
    "print(\"Accuracy:\", report[\"accuracy\"])\n",
    "print(\"Macro-F1:\", report[\"macro_f1\"])\n",
    "print(\"\\nM√©tricas por clase:\")\n",
    "for i, class_label in enumerate(report[\"classes\"]):\n",
    "    print(f\"{class_label}:\")\n",
    "    print(f\"  Precision: {report['precisions'][i]:.4f}\")\n",
    "    print(f\"  Recall: {report['recalls'][i]:.4f}\")\n",
    "    print(f\"  F1-score: {report['f1_scores'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b5c4e",
   "metadata": {},
   "source": [
    "üìä **An√°lisis de los resultados:**\n",
    "\n",
    "**Accuracy: 67.9% vs Macro-F1: 37.2%**: La gran diferencia se debe al desbalance de clases y al rendimiento desigual por clase\n",
    "\n",
    "**M√©tricas por clase**\n",
    "\n",
    "- **mostly true**:  ‚≠ê Clase dominante y bien predicha\n",
    "  - Precision: 0.82 (de los que predijo como esta clase, 82% eran correctos)\n",
    "  - Recall: 0.80 (de los reales de esta clase, 80% fueron encontrados)\n",
    "  - F1: 0.81 (excelente, el modelo predice bien esta clase)\n",
    "\n",
    "- **mostly false**: üö® Problema cr√≠tico\n",
    "  - Precision: 1.00 (cuando predice esta clase, nunca se equivoca)\n",
    "  - Recall: 0.06 (¬°pero casi nunca la predice! Solo 6% de los reales fueron encontrados)\n",
    "  - F1: 0.11 (muy bajo)\n",
    "\n",
    "- **no factual content**: ‚ö†Ô∏è Rendimiento medio\n",
    "  - Precision: 0.50\n",
    "  - Recall: 0.20\n",
    "  - F1: 0.29 (mejor que dar un valor random, pero bajo)\n",
    "\n",
    "- **mixture of true and false**: ‚ö†Ô∏è Rendimiento medio / bajo\n",
    "  - Precision: 0.23 \n",
    "  - Recall: 0.35 \n",
    "  - F1: 0.28 (bajo)\n",
    "\n",
    "\n",
    "**¬øPor qu√© tanta diferencia entre Accuracy y Macro-F1?**\n",
    "\n",
    "Accuracy est√° dominado por la clase \"mostly true\", que el modelo predice muy bien y probablemente es la clase mayoritaria.\n",
    "Macro-F1 penaliza fuertemente el mal desempe√±o en las clases minoritarias (\"mostly false\", \"mixture of true and false\", \"no factual content\").\n",
    "\n",
    " Aunque el accuracy global sea alto, si el modelo ignora o predice mal las clases poco frecuentes, Macro-F1 baja mucho.\n",
    "\n",
    "**Conclusi√≥n:**\n",
    "El modelo parece ser bueno para la clase mayoritaria, pero malo detectando las minoritarias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9a63a",
   "metadata": {},
   "source": [
    "\n",
    "## (d) Orientaci√≥n:\n",
    "\n",
    "Repetir el ejercicio pero para clasificar la orientaci√≥n pol√≠tica del portal donde fue publicada la noticia (izquierda, derecha o mainstream) a partir del texto principal preprocesado. ¬øSiguen siendo v√°lidas las conclusiones extra√≠das anteriormente? Justificar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8936d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.822429906542056\n",
      "Macro-F1: 0.7791249491249491\n",
      "\n",
      "M√©tricas por clase:\n",
      "left:\n",
      "  Precision: 0.6735\n",
      "  Recall: 0.5893\n",
      "  F1-score: 0.6286\n",
      "mainstream:\n",
      "  Precision: 0.8688\n",
      "  Recall: 0.9145\n",
      "  F1-score: 0.8910\n",
      "right:\n",
      "  Precision: 0.8214\n",
      "  Recall: 0.8142\n",
      "  F1-score: 0.8178\n"
     ]
    }
   ],
   "source": [
    "# Cambia la variable objetivo\n",
    "X = df[\"mainText\"]\n",
    "y = df[\"orientation\"]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizaci√≥n\n",
    "vectorizer = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    max_df=0.6,\n",
    "    min_df=3\n",
    ")\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_dense = ensure_dense(X_train_vec)\n",
    "X_test_dense = ensure_dense(X_test_vec)\n",
    "\n",
    "mnb = MNB(alpha=1)\n",
    "mnb.fit(X_train_dense, y_train)\n",
    "report = mnb.classification_report(X_test_dense, y_test)\n",
    "\n",
    "print(\"Accuracy:\", report[\"accuracy\"])\n",
    "print(\"Macro-F1:\", report[\"macro_f1\"])\n",
    "print(\"\\nM√©tricas por clase:\")\n",
    "for i, class_label in enumerate(report[\"classes\"]):\n",
    "    print(f\"{class_label}:\")\n",
    "    print(f\"  Precision: {report['precisions'][i]:.4f}\")\n",
    "    print(f\"  Recall: {report['recalls'][i]:.4f}\")\n",
    "    print(f\"  F1-score: {report['f1_scores'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8539b0",
   "metadata": {},
   "source": [
    "üìä **An√°lisis de los resultados:**\n",
    "\n",
    "- Accuracy (82%): Clasifica correctamente el 82%. Es un valor alto, indicando buen rendimiento general.\n",
    "- Macro-F1 (78%): Tiene mejor rendimiento en ambas clases, no solo en las mayoritarias. Ademas, se parece al valor del accuracy.\n",
    "- Por clase:\n",
    "  - mainstream: ‚≠ê Mejor clase. El modelo es muy bueno (F1: 0.89, precision y recall altos), lo que suele ser esperable si es la clase mayoritaria.\n",
    "  - right: ‚úÖ Desempe√±o parecido (F1: 0.82).\n",
    "  - left: ‚ö†Ô∏è El desempe√±o es menor (F1: 0.63), pero sigue siendo aceptable. Posiblemente menos ejemplos o m√°s dif√≠cil de distinguir\n",
    "\n",
    "**Comparaci√≥n de resultados**\n",
    "- Problema anterior (veracidad):\n",
    "  - Accuracy: 67.9% vs Macro-F1: 37.2% (diferencia de 30.7%)\n",
    "  - Rendimiento muy desigual entre clases\n",
    "- Problema actual (orientaci√≥n pol√≠tica):\n",
    "  - Accuracy: 82.2% vs Macro-F1: 77.9% (diferencia de solo 4.3%)\n",
    "  - Rendimiento mucho m√°s equilibrado\n",
    "\n",
    "**¬øPor qu√© funciona mejor?**\n",
    "Porque las clases est√°n m√°s balanceadas. La orientaci√≥n pol√≠tica parece tener una distribuci√≥n m√°s equilibrada, lo cual coincide con lo visto en el punto a). Esto puede ser porque hay menos ambig√ºedad, la orientaci√≥n pol√≠tica puede ser m√°s f√°cil de detectar que la veracidad de las noticias.\n",
    "\n",
    "**Observaciones importantes**:\n",
    "- Macro-F1 cercano a Accuracy: Indica que el modelo funciona bien en todas las clases\n",
    "- Rendimiento consistente: Ninguna clase est√° siendo completamente ignorada. (en veracidad, \"mostly false\" nunca la detectaba)\n",
    "- Mejora significativa: De 37.2% a 77.9% en Macro-F1 (¬°m√°s del doble!)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-taller",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
